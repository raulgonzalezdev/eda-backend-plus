# Balanceador de Carga NGINX - EDA Backend Plus

## Navegaci√≥n
- Inicio: [README](../README.md)
- Metodolog√≠a: [Metodologia.md](Metodologia.md)
- Observabilidad (APM/OTel): [observability-overview.md](observability-overview.md)
- Resiliencia BD (Patroni + HAProxy): [database-resilience.md](database-resilience.md)
- Balanceador NGINX: [README-LoadBalancer.md](README-LoadBalancer.md)
- Gu√≠a de entrevista: [guia-entrevista-backend.md](guia-entrevista-backend.md)
- Contribuci√≥n (ES): [CONTRIBUTING.es.md](CONTRIBUTING.es.md)
- Contribuci√≥n (EN): [CONTRIBUTING.md](CONTRIBUTING.md)
- Esquema POS y DDL: [pos_schema_instructions.md](pos_schema_instructions.md)
- OpenAPI: [../specs/openapi.yaml](../specs/openapi.yaml) ¬∑ AsyncAPI: [../specs/asyncapi.yaml](../specs/asyncapi.yaml)

## Resumen de Implementaci√≥n

Este documento describe la implementaci√≥n exitosa de un balanceador de carga NGINX con alta disponibilidad y failover autom√°tico para la aplicaci√≥n EDA Backend Plus.

## Arquitectura Implementada

### Componentes
- **3 Instancias de Aplicaci√≥n**: `eda-backend-app1`, `eda-backend-app2`, `eda-backend-app3`
- **Balanceador NGINX**: `nginx-load-balancer`
- **Health Checks**: Verificaci√≥n autom√°tica de salud en `/api/health`
- **Failover Autom√°tico**: Recuperaci√≥n autom√°tica ante fallos

### Puertos de Acceso
- **Puerto 80**: Acceso HTTP est√°ndar
- **Puerto 8085**: Acceso HTTP alternativo (mapeado desde 8080 interno)
- **Puerto 8090**: Puerto para m√©tricas y monitoreo

## üîß Componentes Implementados

### 1. **M√∫ltiples Instancias de Aplicaci√≥n**
- **app1**: Puerto 8081 (eda-backend-app1)
- **app2**: Puerto 8082 (eda-backend-app2)  
- **app3**: Puerto 8083 (eda-backend-app3)

### 2. **NGINX Load Balancer**
- **Puerto 80**: Acceso principal
- **Puerto 8080**: Compatibilidad con configuraci√≥n anterior
- **Puerto 8090**: M√©tricas y monitoreo

### 3. **Health Checks Autom√°ticos**
- **Docker Health Checks**: Cada 30 segundos
- **NGINX Health Checks**: Autom√°ticos con failover
- **Endpoint**: `/api/health`

## ‚öôÔ∏è Configuraci√≥n

### **Docker Compose**
```yaml
# 3 instancias de la aplicaci√≥n
app1, app2, app3:
  - Puertos: 8081, 8082, 8083
  - Health checks cada 30s
  - Restart autom√°tico
  - Variables de entorno individuales

# NGINX Load Balancer
nginx:
  - Puertos: 80, 8080, 8090
  - Configuraci√≥n en ./nginx/nginx.conf
  - Dependencias: app1, app2, app3
```

### **NGINX Configuration**
```nginx
upstream eda_backend {
    least_conn;  # Balanceo por menor conexiones
    server app1:8080 max_fails=3 fail_timeout=30s;
    server app2:8080 max_fails=3 fail_timeout=30s;
    server app3:8080 max_fails=3 fail_timeout=30s;
}
```

## üöÄ C√≥mo Usar

### **1. Iniciar el Sistema**
```powershell
# Construir y levantar todos los servicios
docker-compose up --build -d

# Verificar estado de los contenedores
docker-compose ps
```

### **2. Verificar el Balanceador**
```powershell
# Probar el endpoint principal
curl http://localhost/api/health

# Probar m√∫ltiples requests para ver distribuci√≥n
for ($i=1; $i -le 10; $i++) { 
    curl http://localhost/api/health 
}
```

### **3. Ejecutar Pruebas Automatizadas**
```powershell
# Prueba b√°sica del balanceador
.\scripts\test_load_balancer.ps1

# Prueba con failover simulado
.\scripts\test_load_balancer.ps1 -TestFailover

# Prueba detallada con m√°s requests
.\scripts\test_load_balancer.ps1 -Requests 50 -Verbose
```

## üîç Monitoreo y M√©tricas

### **Endpoints de Monitoreo**
- `http://localhost/health` - Health check del balanceador
- `http://localhost/api/health` - Health check de las aplicaciones
- `http://localhost:8090/metrics` - M√©tricas de NGINX
- `http://localhost/nginx-status` - Estado de NGINX

### **Logs**
```powershell
# Ver logs del balanceador
docker logs nginx-load-balancer

# Ver logs de una instancia espec√≠fica
docker logs eda-backend-app1

# Ver logs de todas las instancias
docker-compose logs app1 app2 app3
```

## üõ†Ô∏è Caracter√≠sticas del Balanceador

### **Estrategias de Balanceo**
- ‚úÖ **Least Connections**: Dirige tr√°fico a la instancia con menos conexiones activas
- ‚úÖ **Health Checks**: Verifica autom√°ticamente la salud de cada instancia
- ‚úÖ **Failover Autom√°tico**: Redirige tr√°fico si una instancia falla
- ‚úÖ **Auto-recovery**: Reintegra instancias cuando se recuperan

### **Configuraci√≥n de Failover**
- **max_fails**: 3 intentos fallidos antes de marcar como down
- **fail_timeout**: 30 segundos antes de reintentar
- **proxy_next_upstream_tries**: 3 intentos en diferentes servidores
- **proxy_next_upstream_timeout**: 10 segundos m√°ximo por intento

### **Headers de Debug**
- `X-Upstream-Server`: Muestra qu√© instancia proces√≥ la request
- `X-Response-Time`: Tiempo de respuesta del upstream

## üß™ Escenarios de Prueba

### **1. Distribuci√≥n Normal**
```powershell
# El tr√°fico se distribuye equitativamente entre las 3 instancias
.\scripts\test_load_balancer.ps1 -Requests 30
```

### **2. Simulaci√≥n de Fallo**
```powershell
# Detiene una instancia y verifica failover autom√°tico
.\scripts\test_load_balancer.ps1 -TestFailover
```

### **3. Recuperaci√≥n Autom√°tica**
```powershell
# Reinicia instancia ca√≠da y verifica reintegraci√≥n
docker start eda-backend-app1
# El balanceador autom√°ticamente incluye la instancia recuperada
```

## üìä M√©tricas y Estad√≠sticas

El script de prueba proporciona:
- **Distribuci√≥n por servidor**: Porcentaje de requests por instancia
- **Tasa de √©xito**: Requests exitosos vs fallidos
- **Tiempo de respuesta**: Latencia promedio
- **Estado de contenedores**: Status de cada instancia

## üîß Troubleshooting

### **Problema: Una instancia no responde**
```powershell
# Verificar logs de la instancia
docker logs eda-backend-app1

# Reiniciar instancia espec√≠fica
docker restart eda-backend-app1
```

### **Problema: NGINX no balancea correctamente**
```powershell
# Verificar configuraci√≥n de NGINX
docker exec nginx-load-balancer nginx -t

# Recargar configuraci√≥n
docker exec nginx-load-balancer nginx -s reload
```

### **Problema: Health checks fallan**
```powershell
# Verificar endpoint de health directamente
curl http://localhost:8081/api/health
curl http://localhost:8082/api/health
curl http://localhost:8083/api/health
```

## üöÄ Pr√≥ximos Pasos

### **Mejoras Planificadas**
1. **Sticky Sessions**: Para aplicaciones que requieren afinidad de sesi√≥n
2. **Rate Limiting**: Protecci√≥n contra ataques DDoS
3. **SSL/TLS**: Terminaci√≥n SSL en el balanceador
4. **M√©tricas Avanzadas**: Integraci√≥n con Prometheus/Grafana
5. **Auto-scaling**: Escalado autom√°tico basado en carga

### **Configuraciones Adicionales**
- **Circuit Breaker**: Protecci√≥n contra cascading failures
- **Retry Logic**: Reintentos inteligentes con backoff
- **Geographic Load Balancing**: Distribuci√≥n por ubicaci√≥n geogr√°fica

## üìù Notas Importantes

- ‚úÖ **Compatibilidad**: El puerto 8080 se mantiene para compatibilidad con configuraciones existentes
- ‚úÖ **Persistencia**: Todas las instancias comparten la misma base de datos PostgreSQL
- ‚úÖ **Kafka**: Las 3 instancias se conectan al mismo cluster de Kafka
- ‚úÖ **Logs**: Cada instancia mantiene logs independientes para debugging
- ‚úÖ **Environment**: Cada instancia tiene un `INSTANCE_ID` √∫nico para identificaci√≥n

### Persistencia de NGINX (DNS din√°mico)
Desde ahora la configuraci√≥n de NGINX incluye resoluci√≥n din√°mica de DNS para los upstreams dentro de Docker. Esto evita tener que reiniciar NGINX cuando se recrean `app1/app2/app3`:

```nginx
http {
  resolver 127.0.0.11 ipv6=off valid=30s;
  resolver_timeout 5s;

  upstream eda_backend {
    least_conn;
    server app1:8080 resolve max_fails=3 fail_timeout=30s weight=1;
    server app2:8080 resolve max_fails=3 fail_timeout=30s weight=1;
    server app3:8080 resolve max_fails=3 fail_timeout=30s weight=1;
  }
}

---

Navegaci√≥n r√°pida: [Volver al README](../README.md) ¬∑ [√çndice de docs](index.md) ¬∑ [Mapa del proyecto](project-map.md) ¬∑ [Gu√≠a de entrevista](guia-entrevista-backend.md) ¬∑ [Observabilidad](observability-overview.md)
```

Adem√°s, el endpoint `/api/health` a√±ade el header `X-Upstream-Server` para diagnosticar qu√© instancia respondi√≥.

## Interpretaci√≥n r√°pida de HAProxy (PostgreSQL)

Esta gu√≠a complementa la secci√≥n de resiliencia de base de datos y explica c√≥mo leer la p√°gina de estad√≠sticas de HAProxy cuando se usa Patroni para gestionar roles de Postgres.

### Puertos y reglas por listener
- `master (5000)`: solo el l√≠der debe aparecer `UP`. R√©plicas aparecer√°n `DOWN` aqu√≠ por no cumplir el rol de escritura.
- `replicas (5001)`: solo r√©plicas deben aparecer `UP`. El l√≠der aparecer√° `DOWN` aqu√≠ por no cumplir el rol de lectura.
- `postgres-cluster (5002)`: los tres nodos deben estar `UP` si el API de Patroni responde al check `/health`; indica salud general del cl√∫ster.

### C√≥mo leer columnas clave
- `Status`: estado del servidor para ese backend. `UP` significa que cumple el rol del listener; `DOWN` suele significar ‚Äúrol no apto para este listener‚Äù, no un fallo del nodo.
- `LastChk`: busca `L7STS/200` (check HTTP pas√≥) o `L7STS/503` (check no cumplido). `503` en `master` para una r√©plica es esperado; en `postgres-cluster` ahora debe ser `200` en todos si `/health` responde.
- `Act/Bck`: distingue servidores activos vs. de respaldo seg√∫n la config. √ötil para ver si alg√∫n nodo est√° marcado como backup.

### Consejos de visualizaci√≥n
- Usa ‚ÄúHide DOWN servers‚Äù en la p√°gina de stats para ver solo los que aplican al listener.
- Para salud global, revisa `postgres-cluster :5002` y confirma `UP` en los tres nodos.

### Verificaci√≥n r√°pida con `psql`
- Escritura (l√≠der): `psql -h localhost -p 5000 -U <usuario> -d <db> -c "create table if not exists lb_probe(x int);"`
- Lectura (r√©plica): `psql -h localhost -p 5001 -U <usuario> -d <db> -c "select now();"`

M√°s detalles: consulta `docs/database-resilience.md`.

## üéØ Beneficios Implementados

1. **Alta Disponibilidad**: Si una instancia falla, las otras contin√∫an funcionando
2. **Escalabilidad**: F√°cil agregar m√°s instancias modificando docker-compose.yml
3. **Performance**: Distribuci√≥n de carga mejora el rendimiento general
4. **Monitoreo**: Visibilidad completa del estado del sistema
5. **Automatizaci√≥n**: Failover y recovery completamente autom√°ticos