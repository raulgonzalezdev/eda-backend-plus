input {
  kafka {
    bootstrap_servers => "${KAFKA_BOOTSTRAP:kafka:9092}"
    topics => ["backend.events"]
    group_id => "logstash-backend-events"
    codec => plain
  }
}

filter {
  # Ensure @timestamp is present and parsed if provided in the event
  # When receiving plain text like {@timestamp:...,status_code:...,endpoint:/api/...}
  if [message] {
    kv {
      source => "message"
      field_split => ","
      value_split => ":"
      include_brackets => true
      trim_key => " @"
    }
  }
  if [@timestamp] {
    date { match => [ "@timestamp", "ISO8601" ] target => "@timestamp" }
  }

  # Normalize fields and add derived ones
  mutate {
    rename => { "endpoint" => "endpoint" }
    convert => { "latency_ms" => "integer" "status_code" => "integer" "amount" => "float" }
    add_field => { "pipeline" => "backend_events" }
  }

  # Optional risk estimation based on amount
  ruby {
    code => '
      amt = event.get("amount")
      if !amt.nil?
        val = amt.to_f
        event.set("risk_level", val >= 10000 ? "high" : "normal")
      end
    '
  }
}

output {
  elasticsearch {
    hosts => ["${ELASTICSEARCH_HOST:http://elasticsearch:9200}"]
    index => "backend.events-%{+YYYY.MM.dd}"
    user => "${ELASTIC_USER:elastic}"
    password => "${ELASTIC_PASSWORD:changeme}"
  }
}